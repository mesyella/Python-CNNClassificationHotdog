{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python 3.6.8\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "d:\\python 3.6.8\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "d:\\python 3.6.8\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "d:\\python 3.6.8\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "d:\\python 3.6.8\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "d:\\python 3.6.8\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageOps\n",
    "\n",
    "testData_Hotdog_Path = 'hotdog_dataset/test/hotdog'\n",
    "testData_notHotdog_Path = 'hotdog_dataset/test/not_hotdog'\n",
    "trainData_Hotdog_Path = 'hotdog_dataset/train/hotdog'\n",
    "trainData_notHotdog_Path = 'hotdog_dataset/train/not_hotdog'\n",
    "valData_Hotdog_Path = 'hotdog_dataset/val/hotdog'\n",
    "valData_notHotdog_Path = 'hotdog_dataset/val/pizza'\n",
    "\n",
    "def train_data():\n",
    "    train_images = []\n",
    "    for i in os.listdir(trainData_Hotdog_Path):\n",
    "        path = os.path.join(trainData_Hotdog_Path,i)\n",
    "        img = Image.open(path)\n",
    "        img = ImageOps.grayscale(img)\n",
    "        img = img.resize((128, 128))\n",
    "        train_images.append([np.array(img), 0])\n",
    "    for i in os.listdir(trainData_notHotdog_Path):\n",
    "        path = os.path.join(trainData_notHotdog_Path,i)\n",
    "        img = Image.open(path)\n",
    "        img = ImageOps.grayscale(img)\n",
    "        img = img.resize((128, 128))\n",
    "        train_images.append([np.array(img), 1])\n",
    "    return train_images\n",
    "\n",
    "def test_data():\n",
    "    test_images = []\n",
    "    for i in os.listdir(testData_Hotdog_Path):\n",
    "        path = os.path.join(testData_Hotdog_Path,i)\n",
    "        img = Image.open(path)\n",
    "        img = ImageOps.grayscale(img)\n",
    "        img = img.resize((128, 128))\n",
    "        test_images.append([np.array(img), 0])\n",
    "        \n",
    "    for i in os.listdir(testData_notHotdog_Path):\n",
    "        path = os.path.join(testData_notHotdog_Path,i)\n",
    "        img = Image.open(path)\n",
    "        img = ImageOps.grayscale(img)\n",
    "        img = img.resize((128, 128))\n",
    "        test_images.append([np.array(img), 1])\n",
    "    return test_images\n",
    "\n",
    "def val_data():\n",
    "    val_images = []\n",
    "    for i in os.listdir(valData_Hotdog_Path):\n",
    "        path = os.path.join(valData_Hotdog_Path,i)\n",
    "        img = Image.open(path)\n",
    "        img = ImageOps.grayscale(img)\n",
    "        img = img.resize((128, 128))\n",
    "        val_images.append([np.array(img), 0])\n",
    "    for i in os.listdir(valData_notHotdog_Path):\n",
    "        path = os.path.join(valData_notHotdog_Path,i)\n",
    "        img = Image.open(path)\n",
    "        img = ImageOps.grayscale(img)\n",
    "        img = img.resize((128, 128))\n",
    "        val_images.append([np.array(img), 1])\n",
    "    return val_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['Hotdog', 'Not-Hotdog']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python 3.6.8\\lib\\site-packages\\PIL\\Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    }
   ],
   "source": [
    "train = train_data()\n",
    "test = test_data()\n",
    "val = val_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 128)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(train[0][0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "xTrain = np.array([i[0] for i in train]).reshape(-1,128,128,1)\n",
    "yTrain = np.array([i[1] for i in train])\n",
    "yTrain = tf.keras.utils.to_categorical(yTrain, num_classes = 2)\n",
    "xVal = np.array([i[0] for i in val]).reshape(-1,128,128,1)\n",
    "yVal = np.array([i[1] for i in val])\n",
    "yVal = tf.keras.utils.to_categorical(yVal, num_classes = 2)\n",
    "xTest = np.array([i[0] for i in test]).reshape(-1,128,128,1)\n",
    "yTest = np.array([i[1] for i in test])\n",
    "yTest = tf.keras.utils.to_categorical(yTest, num_classes = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 128, 128, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xTrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yTrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(128, 128,1)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Conv2D(32, kernel_size=(3, 3), activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Dropout(0.25),\n",
    "    tf.keras.layers.Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.25),\n",
    "    tf.keras.layers.Conv2D(128, kernel_size=(3, 3), activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Dropout(0.25),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.25),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.25),\n",
    "    tf.keras.layers.Dense(2, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=tf.keras.losses.categorical_crossentropy, optimizer=tf.keras.optimizers.Adam(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 120 samples, validate on 32 samples\n",
      "Epoch 1/5\n",
      "120/120 [==============================] - 69s 577ms/step - loss: 0.9531 - acc: 0.6417 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 2/5\n",
      "120/120 [==============================] - 54s 452ms/step - loss: 0.2944 - acc: 0.8500 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 3/5\n",
      "120/120 [==============================] - 61s 507ms/step - loss: 0.2021 - acc: 0.9000 - val_loss: 5.4714 - val_acc: 0.5000\n",
      "Epoch 4/5\n",
      "120/120 [==============================] - 62s 517ms/step - loss: 0.1435 - acc: 0.9667 - val_loss: 1.1681 - val_acc: 0.6875\n",
      "Epoch 5/5\n",
      "120/120 [==============================] - 69s 575ms/step - loss: 0.1484 - acc: 0.9583 - val_loss: 1.5881 - val_acc: 0.6875\n"
     ]
    }
   ],
   "source": [
    "train = model.fit(xTrain, yTrain, epochs = 5, validation_data=(xVal, yVal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(xTest, yTest, batch_size=128, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss, test acc: [2.4658267498016357, 0.6363636255264282]\n"
     ]
    }
   ],
   "source": [
    "print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(50,50))\n",
    "for i in range(120):\n",
    "    plt.subplot(12,10,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(tr_img_data[i], cmap=plt.cm.binary)\n",
    "    plt.xlabel(class_names[tr_lbl_data[i]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential() \n",
    "model.add(tf.keras.layers.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(305, 305))) \n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2))) \n",
    "model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu')) \n",
    "model.add(tf.keras.layers.Dropout(0.25)) \n",
    "model.add(tf.keras.layers.Dense(128, activation='relu')) \n",
    "model.add(tf.keras.layers.Dropout(0.5)) \n",
    "model.add(tf.keras.layers.Flatten()) \n",
    "model.add(tf.keras.layers.Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=tf.keras.losses.categorical_crossentropy, optimizer=tf.keras.optimizers.Adadelta(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = model.fit(tr_img_data, tr_lbl_data, batch_size=128, epochs=3, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
